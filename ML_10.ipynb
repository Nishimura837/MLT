{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam, SGD\n",
    "from optuna.samplers import TPESampler, GridSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.csv,train.csvを取得\n",
    "X_train_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/X_train.csv\"\n",
    "y_train_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/y_train.csv\"\n",
    "X_test_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/X_test.csv\"\n",
    "y_test_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/y_test.csv\"\n",
    "df_train_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/df_train.csv\"\n",
    "df_test_path = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/df_test.csv\"\n",
    "\n",
    "# Numpy配列としてよみこむ\n",
    "X_train = pd.read_csv(X_train_path)\n",
    "y_train = pd.read_csv(y_train_path)\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_test = pd.read_csv(y_test_path)\n",
    "\n",
    "# dfはDataFrameとしてよみこむ\n",
    "df_train = pd.read_csv(df_train_path)\n",
    "df_test = pd.read_csv(df_test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "folds = 10\n",
    "\n",
    "def create_model(trial):\n",
    "    inputs = Input(shape=())\n",
    "\n",
    "    # 入力層を作成\n",
    "    x = Dense(25, activation='relu', input_dim=25)(inputs)\n",
    "\n",
    "    # 中間層の作成\n",
    "    # ハイパーパラメータの最適化\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 5)\n",
    "    units = trial.suggest_int('n_units', 8, 256, step=8)\n",
    "    for i in range(n_layers):\n",
    "        x = Dense(units=units, activation='relu')(x)\n",
    "\n",
    "    # 出力層の作成\n",
    "    predictions = Dense(1)(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "    # オプティマイザと学習率の最適化\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'RMSProp'])\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam()\n",
    "    if optimizer_name == 'sgd':\n",
    "        optimizer = SGD(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = 'RMSProp'\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    # モデルの作成\n",
    "    model = create_model(trial)\n",
    "\n",
    "    # batch_size範囲を指定\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 256, step=16)\n",
    "\n",
    "    # KFold のオブジェクトを作成\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "\n",
    "    \n",
    "    for train_index, valid_index in kf.split(X_train):\n",
    "        X_train_subset = X_train.loc[train_index].values\n",
    "        y_train_subset = y_train.loc[train_index].values\n",
    "        X_valid_subset = X_train.loc[valid_index].values\n",
    "        y_valid_subset = y_train.loc[valid_index].values\n",
    "\n",
    "        # トレーニング\n",
    "        model.fit(\n",
    "            X_train_subset, y_train_subset, \n",
    "            batch_size=batch_size,\n",
    "            epochs=100, \n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # 予測\n",
    "        y_pred = model.predict(X_valid_subset)\n",
    "\n",
    "        # NaN が含まれているか確認\n",
    "        if np.isnan(y_pred).any():\n",
    "            print(\" NaN が含まれているので関数から抜け出します。\")\n",
    "            return \n",
    "\n",
    "        # RMSEを算出\n",
    "        temp_rmse_valid = np.sqrt(mean_squared_error(y_valid_subset, y_pred))\n",
    "\n",
    "        # RMSEをリストにappend\n",
    "        rmses.append(temp_rmse_valid)\n",
    "\n",
    "        # CVのRMSEの平均値を目的関数として返す\n",
    "        return np.mean(rmses)\n",
    "    \n",
    "\n",
    "# ------------------------------------\n",
    "# # ベイズ最適化\n",
    "sampler = TPESampler()\n",
    "study = optuna.create_study(sampler=sampler, direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print('Number of finalized trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "# 最適なパラメータの表示\n",
    "\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "y_train = y_train.values\n",
    "X_test = X_test.values\n",
    "y_test = y_test.values\n",
    "\n",
    "best_batch_size = study.best_trial.params['batch_size']\n",
    "print(best_batch_size)\n",
    "# 最適なパラメータを使ってモデルの作成\n",
    "best_model = create_model(study.best_trial)\n",
    "train_history = best_model.fit(\n",
    "                                X_train, y_train, \n",
    "                                batch_size=best_batch_size,\n",
    "                                epochs=100, \n",
    "                                verbose=0\n",
    "                            )\n",
    "\n",
    "print(train_history.history.keys())\n",
    "\n",
    "print(train_history.history)\n",
    "print(len(train_history.history['loss']))\n",
    "\n",
    "# エポックごとの損失関数値をプロットしてみる\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(train_history.history['loss'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "# 評価\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Final MSE on test data:', final_mse)\n",
    "# print(y_test_pred)\n",
    "\n",
    "\n",
    "# 図を作成するための準備\n",
    "df_train['predict values'] = y_train_pred\n",
    "df_train['residuals'] = y_train_pred - y_train\n",
    "df_test['predict values'] = y_test_pred\n",
    "df_test['residuals'] = y_test_pred - y_test\n",
    "\n",
    "\n",
    "#df_trainに'legend'列を追加(凡例)\n",
    "root_directory = \"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/\"\n",
    "for folder_name in os.listdir(root_directory):  \n",
    "        for index,row in df_train.iterrows() :           #１行ずつ実行\n",
    "                if folder_name + '_' in row['case_name']:                 #case_nameにfolder_nameが含まれているかどうか\n",
    "                        df_train.loc[index,'legend'] = 'Training:' + folder_name\n",
    "\n",
    "df_test['legend'] = 'Test data'\n",
    "\n",
    "df_forfig = pd.concat([df_train, df_test])\n",
    "# df_forfig.to_csv(\"/home/gakubu/デスクトップ/ML_git/MLT/ML_9/ML_9_5/df_forfig XGB.csv\"\\\n",
    "#                         ,encoding='utf_8_sig', index=False)\n",
    "\n",
    "#-----Error Evaluation (+test) DTR.pdfの作成-------------------------------------------\n",
    "# 各オフィス名に対する色を 'tab20' カラーマップから取得\n",
    "legend_names = df_train['legend'].unique()      #unique()メソッドは指定した列内の一意の値の配列を返す（重複を取り除く）\n",
    "# print(legend_names)\n",
    "colors = plt.cm.tab20(range(len(legend_names))) #tab20から配列legemd_namesの長さ分の色の配列colorsを返す\n",
    "# 凡例名と色の対応を辞書に格納\n",
    "# zip関数は２つ以上のリストを取り、それらの対応する要素をペアにしてイテレータを返す。\n",
    "# この場合、legend_namesとcolorsの２つのリストをペアにし、対応する要素同士を取得する。\n",
    "# =以降はofficeをキーとしてそれに対応するcolorが\"値\"として格納される辞書を作成\n",
    "legend_color_mapping = {legend: color for legend, color in zip(legend_names, colors)}\n",
    "# print(legend_color_mapping)\n",
    "# 'legend' 列を数値（色情報に対応する数値）に変換\n",
    "# 'legend_num'　を追加\n",
    "df_train['legend_num'] = df_train['legend'].map(legend_color_mapping)\n",
    "#散布図を作成\n",
    "plt.scatter(df_train['predict values'], df_train['residuals'], c=df_train['legend_num'])\n",
    "plt.scatter(df_test['predict values'], df_test['residuals'], c='black', marker='x' )\n",
    "#y=0の直線を引く\n",
    "# y = 0 の直線を描く\n",
    "plt.axhline(y=0, color='black', linestyle='-')\n",
    "\n",
    "# 凡例を作成\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, \\\n",
    "                        markersize=6, label=legend) for legend, color in zip(legend_names, colors)]\n",
    "# Test dataの凡例を追加\n",
    "handles[-1] = plt.Line2D([0], [0] ,marker='x', color='black', markersize=6, label='Test data', linestyle='None')\n",
    "\n",
    "# 凡例を表示\n",
    "plt.legend(handles=handles, loc='upper left', fontsize=6)\n",
    "\n",
    "\n",
    "plt.title('Error Evaluation ML_10_trial_op3')\n",
    "plt.savefig(\"/home/gakubu/デスクトップ/ML_git/MLT/ML_10/Error Evaluation 10 trial op3.pdf\", format='pdf') \n",
    "# plt.show()\n",
    "#-----------------------------------------------------------------------------------\n",
    "\n",
    "print('Finished ML_10_trial_op3.py')\n",
    "\n",
    "\n",
    "\n",
    "#各種評価指標をcsvファイルとして出力する\n",
    "df_ee = pd.DataFrame({'R^2(決定係数)': [r2_score(y_test, y_test_pred)],\n",
    "                        'RMSE(二乗平均平方根誤差)': [np.sqrt(mean_squared_error(y_test, y_test_pred))],\n",
    "                        'MSE(平均二乗誤差)': [mean_squared_error(y_test, y_test_pred)],\n",
    "                        'MAE(平均絶対誤差)': [mean_absolute_error(y_test, y_test_pred)]})\n",
    "df_ee.to_csv(\"/home/gakubu/デスクトップ/ML_git/MLT/ML_10/Error Evaluation 10 trial op3.csv\",encoding='utf_8_sig', index=False)\n",
    "\n",
    "df_ee_train = pd.DataFrame({'R^2(決定係数)': [r2_score(y_train, y_train_pred)],\n",
    "                        'RMSE(二乗平均平方根誤差)': [np.sqrt(mean_squared_error(y_train, y_train_pred))],\n",
    "                        'MSE(平均二乗誤差)': [mean_squared_error(y_train, y_train_pred)],\n",
    "                        'MAE(平均絶対誤差)': [mean_absolute_error(y_train, y_train_pred)]})\n",
    "df_ee_train.to_csv(\"/home/gakubu/デスクトップ/ML_git/MLT/ML_10/Error Evaluation 10 trial op3 train.csv\",encoding='utf_8_sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
